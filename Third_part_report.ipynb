{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Part Report \n",
    "\n",
    "### introduction\n",
    "This competition I apply [Hugging face](https://huggingface.co/) to handling transformer text classification, the **env installation** is based on [this link](https://huggingface.co/docs/transformers/main/en/installation). The report will split into three parts : **data preprocessing, training, and evaluation(make submission csv)**\n",
    "\n",
    "#### What is Hugging Face Transformer?\n",
    "Hugging Face Transformers provides APIs and tools to **easily download and train state-of-the-art pretrained models**. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Part : Data Preprocessing \n",
    "\n",
    "load lines of tweet record from tweets_DM.json into a list called **data**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_score': 391, '_index': 'hashtag_tweets', '_source': {'tweet': {'hashtags': ['Snapchat'], 'tweet_id': '0x376b20', 'text': 'People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that\\'s <LH>'}}, '_crawldate': '2015-05-23 11:42:47', '_type': 'tweets'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open('data/tweets_DM.json','r', encoding='utf')\n",
    "data = []\n",
    "for line in f.readlines():\n",
    "    dic = json.loads(line)\n",
    "    data.append(dic)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take **tweet_id** and **text** feature to make a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text\n",
       "0  0x376b20  People who post \"add me on #Snapchat\" must be ...\n",
       "1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n",
       "2  0x28b412  Confident of your obedience, I write to you, k...\n",
       "3  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>\n",
       "4  0x2de201  \"Trust is not the same as faith. A friend is s..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dic = {\n",
    "    'tweet_id':[],\n",
    "    'text':[]\n",
    "}\n",
    "for d in data:\n",
    "    for key in dic.keys():\n",
    "        dic[key].append(d['_source']['tweet'][key])\n",
    "\n",
    "tweet_df = pd.DataFrame(dic)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read emotion label from emotion.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id       emotion\n",
       "0  0x3140b1       sadness\n",
       "1  0x368b73       disgust\n",
       "2  0x296183  anticipation\n",
       "3  0x2bd6e1           joy\n",
       "4  0x2ee1dd  anticipation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_df = pd.read_csv('data/emotion.csv')\n",
    "emo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id identification\n",
       "0  0x28cc61           test\n",
       "1  0x29e452          train\n",
       "2  0x2b3819          train\n",
       "3  0x2db41f           test\n",
       "4  0x2a2acc          train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_id_df = pd.read_csv('data/data_identification.csv')\n",
    "data_id_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge tweet_df and data_id_df base on tweet_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text identification\n",
       "0  0x376b20  People who post \"add me on #Snapchat\" must be ...          train\n",
       "1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...          train\n",
       "2  0x28b412  Confident of your obedience, I write to you, k...           test\n",
       "3  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>          train\n",
       "4  0x2de201  \"Trust is not the same as faith. A friend is s...           test"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df = pd.merge(tweet_df, data_id_df, on = 'tweet_id')\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1455563, 3), (411972, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = merge_df.loc[merge_df['identification'] == 'train']\n",
    "test_df = merge_df.loc[merge_df['identification'] == 'test']\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode emotion label into number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text identification  \\\n",
       "0  0x376b20  People who post \"add me on #Snapchat\" must be ...          train   \n",
       "1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...          train   \n",
       "2  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>          train   \n",
       "3  0x1d755c  @RISKshow @TheKevinAllison Thx for the BEST TI...          train   \n",
       "4  0x2c91a8       Still waiting on those supplies Liscus. <LH>          train   \n",
       "\n",
       "   emotion  \n",
       "0        1  \n",
       "1        5  \n",
       "2        3  \n",
       "3        4  \n",
       "4        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_df = pd.merge(train_df, emo_df, on = 'tweet_id')\n",
    "emo_label_encoder = LabelEncoder()\n",
    "train_df['emotion'] = emo_label_encoder.fit_transform(train_df['emotion'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /homes/jinyu/.conda/envs/DM/lib/python3.10/site-packages (3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from emot.emo_unicode import EMOJI_UNICODE\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "with open('Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def convert_emojis(text):\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\" \").replace(\":\",\" \").split()), text)\n",
    "        text = text.replace('_', \" \")\n",
    "    return text\n",
    "\n",
    "train_df['text'] = train_df['text'].progress_apply(convert_emojis)\n",
    "test_df['text'] = test_df['text'].progress_apply(convert_emojis)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save data into pkl file than we can load in trianing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "test_df.to_csv('data/test_df.csv')\n",
    "test_df.head()\n",
    "train_texts = train_df['text'].to_list()\n",
    "test_texts = test_df['text'].to_list()\n",
    "train_labels = train_df['emotion'].tolist()\n",
    "\n",
    "with open('data/train_texts.pickle', 'wb') as f:\n",
    "    pickle.dump(train_texts, f)\n",
    "with open('data/test_texts.pickle', 'wb') as f:\n",
    "    pickle.dump(test_texts, f)\n",
    "with open('data/train_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(train_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now ISSA is stalking Tasha face with tears of joyface with tears of joyface with tears of joy\n"
     ]
    }
   ],
   "source": [
    "print(convert_emojis(\"Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Part: Training \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a new dataset class with torch dataset type, and define **PATH** (if path is a checkpoint path, the training process can start from checkpoint state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "PATH = None\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_texts.pickle', 'rb') as f:\n",
    "    train_texts = pickle.load(f)\n",
    "with open('data/test_texts.pickle', 'rb') as f:\n",
    "    test_texts = pickle.load(f)\n",
    "with open('data/train_labels.pickle', 'rb') as f:\n",
    "    train_labels = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chosed [RoBERTa](https://huggingface.co/roberta-base?text=The+goal+of+life+is+%3Cmask%3E.) as transformer architecture, and use [pretrained model](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base?text=Oh+wow.+I+didn%27t+know+that.) pretrained by Hartmann and Jochen. The model is pretrain on **six emtion english text datasets**(MELD, Crowdflower, GoEmotions...). So I load the tokenizer by the pretrain model checkpoints and encode the training text and define our training dataset. Next, Load the pretrained model, because the pretrained model was trained on 7 labels, however, our task is 8 labels. So the arguments **num_labels** should set 8, **ignore_mismatched_sizes** set True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PATH == None:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(PATH)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encoding = tokenizer(train_texts[:100], truncation=True, padding=True)\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset = TweetDataset(val_encoding, train_labels[:100])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "if PATH == None:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", num_labels=8, ignore_mismatched_sizes=True).to(\"cuda\")\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(PATH).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training argument and trainer, set learning rate, batch size, weight decay... arguments. The **gradient_accumulation_steps** means the model will update weight every 16 steps instead of every step. I set this argument is because my GPU mem is not big enough to larger batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_v3\",\n",
    "    learning_rate=2.0e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit = 20,\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps = 2500,\n",
    "    gradient_accumulation_steps = 16\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "if PATH == None:\n",
    "    trainer.train()\n",
    "else:\n",
    "    trainer.train(PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Partï¼š Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read text df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  tweet_id                                               text  \\\n",
       "0           2  0x28b412  Confident of your obedience, I write to you, k...   \n",
       "1           4  0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "2           9  0x218443  When do you have enough ? When are you satisfi...   \n",
       "3          30  0x2939d5  God woke you up, now chase the day #GodsPlan #...   \n",
       "4          33  0x26289a  In these tough times, who do YOU turn to as yo...   \n",
       "\n",
       "  identification  \n",
       "0           test  \n",
       "1           test  \n",
       "2           test  \n",
       "3           test  \n",
       "4           test  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/test_df.csv\", lineterminator='\\n')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define checkpoint path saved in training part. and encode the text data, define the test data set with dummy labels, and load the model and tokenizer by checkpoints path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = \"results_v3/checkpoint-85000\"\n",
    "size = test_df.shape[0]\n",
    "dummy_labels = size * [0]\n",
    "test_texts = test_df['text'].to_list()\n",
    "test_df['emotion'] = \"\"\n",
    "emo_labels = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness',\n",
    "       'surprise', 'trust']\n",
    "model = AutoModelForSequenceClassification.from_pretrained(CKPT_PATH).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CKPT_PATH)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "test_dataset = TweetDataset(test_encodings, dummy_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the training argument and use the trainer to predict emo label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_args = TrainingArguments(\n",
    "    output_dir = './other',\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = 50,   \n",
    "    dataloader_drop_last = False    \n",
    ")\n",
    "\n",
    "# init trainer\n",
    "trainer = Trainer(\n",
    "              model = model, \n",
    "              args = test_args)\n",
    "\n",
    "test_results = trainer.predict(test_dataset)\n",
    "test_results_list = list(np.argmax(test_results.predictions, axis=-1))\n",
    "pred = list(map(lambda x : emo_labels[x], test_results_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save submision csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_df[\"tweet_id\"].tolist()\n",
    "dic = {\n",
    "    \"id\": ids,\n",
    "    \"emotion\": pred\n",
    "}\n",
    "df = pd.DataFrame(dic, )\n",
    "df.to_csv(\"submission20221115_85000iter.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33a5466597607f5807ee7584e8b053d73c4d4ccd4abfacbb260ac6272a9b808d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
